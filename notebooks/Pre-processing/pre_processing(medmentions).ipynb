{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6d70ca0",
   "metadata": {},
   "source": [
    "# MedMentions Dataset Preprocessing\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook preprocesses the MedMentions dataset for entity linking with the UMLS knowledge base.\n",
    "\n",
    "**Dataset:** 352K+ entity mentions from 4K PubMed biomedical abstracts\n",
    "**Knowledge Base:** UMLS (Unified Medical Language System) - different from Wikipedia\n",
    "**Challenge:** High ambiguity, especially in medical abbreviations (MS, RA, CA)\n",
    "\n",
    "**Preprocessing Pipeline:**\n",
    "1. Load and parse PubTator format ‚Üí Extract mentions with UMLS CUIDs\n",
    "2. Filter valid entities ‚Üí Remove corrupted annotations\n",
    "3. Normalize mentions ‚Üí Standardize medical terminology\n",
    "4. Extract biomedical features ‚Üí Add domain-specific attributes\n",
    "5. Create structured records ‚Üí Format for entity linking models\n",
    "6. Export data ‚Üí Save as JSONL and Parquet\n",
    "7. Generate statistics ‚Üí Document dataset characteristics\n",
    "\n",
    "---\n",
    "\n",
    "## Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85057124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de3ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "import Utils as u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f9b6f",
   "metadata": {},
   "source": [
    "## Step 1: Load MedMentions Dataset\n",
    "\n",
    "**Purpose:** Parse the PubTator format file and split data by official train/dev/test PMIDs.\n",
    "\n",
    "**What it does:**\n",
    "- Reads corpus_pubtator.txt (biomedical abstracts with entity annotations)\n",
    "- Extracts mentions with UMLS Concept Unique Identifiers (CUIDs)\n",
    "- Adds 200-character context windows around each mention\n",
    "- Splits data according to official train/dev/test document lists\n",
    "\n",
    "**Dataset structure:** Each mention includes:\n",
    "- `pmid`: PubMed document ID\n",
    "- `mention`: Entity text (e.g., \"diabetes\", \"MS\")\n",
    "- `entity_id`: UMLS CUID (e.g., \"C0011849\")\n",
    "- `entity_type`: UMLS semantic type (e.g., \"Disease or Syndrome\")\n",
    "- Context fields for disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8094d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MEDMENTIONS DATASET\n",
      "Parsing data/MedMentions/corpus_pubtator.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "365672it [00:02, 128875.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 352496 mentions from 4392 documents\n",
      "\n",
      "Total mentions: 352,496\n",
      "Total PMIDs: 4,392\n",
      "Total unique UMLS entities: 34,724\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CORPUS_PATH = 'data/MedMentions/corpus_pubtator.txt'\n",
    "TRAIN_PMIDS_PATH = 'data/MedMentions/corpus_pubtator_pmids_trng.txt'\n",
    "DEV_PMIDS_PATH = 'data/MedMentions/corpus_pubtator_pmids_dev.txt'\n",
    "TEST_PMIDS_PATH = 'data/MedMentions/corpus_pubtator_pmids_test.txt'\n",
    "\n",
    "print(\"LOADING MEDMENTIONS DATASET\")\n",
    "\n",
    "mentions_list = u.parse_pubtator_file(CORPUS_PATH)\n",
    "df_all = pd.DataFrame(mentions_list)\n",
    "\n",
    "print(f\"\\nTotal mentions: {len(df_all):,}\")\n",
    "print(f\"Total PMIDs: {df_all['pmid'].nunique():,}\")\n",
    "print(f\"Total unique UMLS entities: {df_all['entity_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f6c387b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading train/dev/test splits...\n",
      "\n",
      " Split Statistics:\n",
      "Train: 211,029 mentions from 2,635 documents\n",
      "Val:   71,062 mentions from 878 documents\n",
      "Test:  70,405 mentions from 879 documents\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading train/dev/test splits...\")\n",
    "\n",
    "with open(TRAIN_PMIDS_PATH, 'r') as f:\n",
    "    train_pmids = set(f.read().splitlines())\n",
    "\n",
    "with open(DEV_PMIDS_PATH, 'r') as f:\n",
    "    dev_pmids = set(f.read().splitlines())\n",
    "\n",
    "with open(TEST_PMIDS_PATH, 'r') as f:\n",
    "    test_pmids = set(f.read().splitlines())\n",
    "\n",
    "\n",
    "df_train = df_all[df_all['pmid'].isin(train_pmids)].copy()\n",
    "df_val = df_all[df_all['pmid'].isin(dev_pmids)].copy()\n",
    "df_test = df_all[df_all['pmid'].isin(test_pmids)].copy()\n",
    "\n",
    "print(f\"\\n Split Statistics:\")\n",
    "print(f\"Train: {len(df_train):,} mentions from {df_train['pmid'].nunique():,} documents\")\n",
    "print(f\"Val:   {len(df_val):,} mentions from {df_val['pmid'].nunique():,} documents\")\n",
    "print(f\"Test:  {len(df_test):,} mentions from {df_test['pmid'].nunique():,} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec31d062",
   "metadata": {},
   "source": [
    "## Step 2: Filter Valid Entities\n",
    "\n",
    "**Purpose:** Remove mentions with invalid or missing UMLS CUIDs to ensure data quality.\n",
    "\n",
    "**What it does:**\n",
    "- Validates that each mention has a proper UMLS identifier\n",
    "- Removes corrupted or incomplete entity annotations\n",
    "- Ensures entity spans match the actual text\n",
    "- Filters out malformed entries\n",
    "\n",
    "**Why it matters:** MedMentions can have parsing errors or incomplete annotations. Clean data prevents training issues and improves model reliability. This is especially important for biomedical data where entity IDs must match the UMLS knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f30125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering valid entities...\n",
      "\n",
      "Train:\n",
      "Original: 211,029 | Valid: 211,029 | Removed: 0 (0.00%)\n",
      "\n",
      "Val:\n",
      "Original: 71,062 | Valid: 71,062 | Removed: 0 (0.00%)\n",
      "\n",
      "Test:\n",
      "Original: 70,405 | Valid: 70,405 | Removed: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Filtering valid entities...\")\n",
    "print(\"\\nTrain:\")\n",
    "df_train = u.apply_filter_valid_entities(df_train)\n",
    "print(\"\\nVal:\")\n",
    "df_val = u.apply_filter_valid_entities(df_val)\n",
    "print(\"\\nTest:\")\n",
    "df_test = u.apply_filter_valid_entities(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04c8880",
   "metadata": {},
   "source": [
    "## Step 3: Normalize Mentions\n",
    "\n",
    "**Purpose:** Standardize medical terminology for consistent matching across variations.\n",
    "\n",
    "**What it does:**\n",
    "- Converts to lowercase (except abbreviations)\n",
    "- Removes extra whitespace and special characters\n",
    "- Strips edge punctuation\n",
    "- Creates `normalized_mention` field\n",
    "\n",
    "**Medical examples:**\n",
    "- \"Type II diabetes\" ‚Üí \"type ii diabetes\"\n",
    "- \"COVID-19\" ‚Üí \"covid-19\"\n",
    "- \"rheumatoid arthritis (RA)\" ‚Üí \"rheumatoid arthritis ra\"\n",
    "\n",
    "**Why it matters:** Medical texts use inconsistent formatting. Normalization helps match \"Diabetes Mellitus\", \"diabetes mellitus\", and \"DIABETES MELLITUS\" to the same UMLS concept, improving entity linking accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4f45aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing mentions...\n",
      "\n",
      "Examples:\n",
      "\n",
      " Normalization complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_train['normalized_mention'] = df_train['mention'].apply(u.normalize_mention)\n",
    "df_val['normalized_mention'] = df_val['mention'].apply(u.normalize_mention)\n",
    "df_test['normalized_mention'] = df_test['mention'].apply(u.normalize_mention)\n",
    "\n",
    "print(\"\\nExamples:\")\n",
    "sample = df_train.head(10)\n",
    "for orig, norm in zip(sample['mention'], sample['normalized_mention']):\n",
    "    if orig != norm:\n",
    "        print(f\"  '{orig}' ‚Üí '{norm}'\")\n",
    "\n",
    "print(\"\\n Normalization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5aa794",
   "metadata": {},
   "source": [
    "## Step 4: Extract Biomedical Features\n",
    "\n",
    "**Purpose:** Add domain-specific features that help disambiguate medical entities.\n",
    "\n",
    "**What it does:**\n",
    "- `is_abbreviation`: Detects ALL CAPS short forms (MS, RA, CA, DNA)\n",
    "- `mention_length`: Character count for the mention\n",
    "- `mention_word_count`: Number of words in mention\n",
    "- `context_length`: Word count in surrounding text\n",
    "- `semantic_type_main`: Primary UMLS semantic type\n",
    "- `is_multi_word`: Whether mention spans multiple words\n",
    "\n",
    "**Why these features matter:**\n",
    "- **Abbreviations** are 2-3x more ambiguous (e.g., \"MS\" = Multiple Sclerosis, Mass Spectrometry, Mississippi)\n",
    "- **Semantic types** provide category hints (Disease vs Procedure vs Chemical)\n",
    "- **Context length** indicates disambiguation difficulty\n",
    "- **Multi-word terms** tend to be more specific\n",
    "\n",
    "**Output:** Enhanced dataset with features for both analysis and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591719b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting biomedical features...\n",
      "\n",
      " Feature Statistics (Train):\n",
      "Abbreviations: 17,526 (8.3%)\n",
      "Mean mention length: 10.7 chars\n",
      "Mean context length: 56.8 words\n",
      "Mean words per mention: 1.37\n",
      "\n",
      "Top 5 semantic types:\n",
      "semantic_type_main\n",
      "T080    18689\n",
      "T169    14241\n",
      "T081    11888\n",
      "T033     9511\n",
      "T116     9194\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting biomedical features...\")\n",
    "\n",
    "df_train = u.extract_biomedical_features(df_train)\n",
    "df_val = u.extract_biomedical_features(df_val)\n",
    "df_test = u.extract_biomedical_features(df_test)\n",
    "\n",
    "print(\"\\n Feature Statistics (Train):\")\n",
    "print(f\"Abbreviations: {df_train['is_abbreviation'].sum():,} ({df_train['is_abbreviation'].mean()*100:.1f}%)\")\n",
    "print(f\"Mean mention length: {df_train['mention_length'].mean():.1f} chars\")\n",
    "print(f\"Mean context length: {df_train['context_length'].mean():.1f} words\")\n",
    "print(f\"Mean words per mention: {df_train['mention_word_count'].mean():.2f}\")\n",
    "print(f\"\\nTop 5 semantic types:\")\n",
    "print(df_train['semantic_type_main'].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9119823",
   "metadata": {},
   "source": [
    "## Step 5: Create Mention-Candidate Pairs\n",
    "\n",
    "**Purpose:** Transform raw data into standardized format for entity linking models.\n",
    "\n",
    "**What it does:**\n",
    "- Creates structured record for each mention\n",
    "- Includes original mention, normalized form, and context\n",
    "- Adds entity ID (ground truth for training)\n",
    "- Bundles all features into unified format\n",
    "\n",
    "**Record structure:**\n",
    "```json\n",
    "{\n",
    "  \"mention\": \"diabetes\",\n",
    "  \"normalized_mention\": \"diabetes\",\n",
    "  \"context_left\": \"...patients with...\",\n",
    "  \"context_right\": \"...mellitus type 2...\",\n",
    "  \"entity_id\": \"C0011849\",\n",
    "  \"entity_type\": \"Disease or Syndrome\",\n",
    "  \"features\": { ... }\n",
    "}\n",
    "```\n",
    "\n",
    "**Why it matters:** This standardized format enables easy integration with various entity linking models (bi-encoders, cross-encoders, retrieval systems). The structure matches what Clarify-and-Link expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb14ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating standardized mention records...\n",
      "\n",
      "Created 211,029 train records\n",
      "Created 71,062 val records\n",
      "Created 70,405 test records\n",
      "\n",
      " Example record:\n",
      "{\n",
      "  \"pmid\": \"25763772\",\n",
      "  \"mention\": \"DCTN4\",\n",
      "  \"normalized_mention\": \"DCTN4\",\n",
      "  \"context_left\": \"\",\n",
      "  \"context_right\": \" as a modifier of chronic Pseudomonas aeruginosa infection in cystic fibrosis Pseudomonas aeruginosa (Pa) infection in cystic fibrosis (CF) patients is associated with worse long-term pulmonary diseas\",\n",
      "  \"full_context\": \" DCTN4  as a modifier of chronic Pseudomonas aeruginosa infection in cystic fibrosis Pseudomonas aeruginosa (Pa) infection in cystic fibrosis (CF) patients is associated with worse long-term pulmonary diseas\",\n",
      "  \"label_id\": \"C4308010\",\n",
      "  \"entity_type\": \"T116,T123\",\n",
      "  \"semantic_type_main\": \"T116\",\n",
      "  \"start\": 0,\n",
      "  \"end\": 5,\n",
      "  \"is_abbreviation\": true,\n",
      "  \"mention_length\": 5,\n",
      "  \"mention_word_count\": 1,\n",
      "  \"context_length\": 28,\n",
      "  \"title\": \"DCTN4 as a modifier of chronic Pseudomonas aeruginosa infection in cystic fibrosis\",\n",
      "  \"abstract\": \"Pseudomonas aeruginosa (Pa) infection in cystic fibrosis (CF) patients is associated with worse long-term pulmonary disease and shorter survival, and chronic Pa infection (CPA) is associated with reduced lung function, faster rate of lung decline, increased rates of exacerbations and shorter survival. By using exome sequencing and extreme phenotype design, it was recently shown that isoforms of dynactin 4 (DCTN4) may influence Pa infection in CF, leading to worse respiratory disease. The purpose of this study was to investigate the role of DCTN4 missense variants on Pa infection incidence, age at first Pa infection and chronic Pa infection incidence in a cohort of adult CF patients from a single centre. Polymerase chain reaction and direct sequencing were used to screen DNA samples for DCTN4 variants. A total of 121 adult CF patients from the Cochin Hospital CF centre have been included, all of them carrying two CFTR defects: 103 developed at least 1 pulmonary infection with Pa, and 68 patients of them had CPA. DCTN4 variants were identified in 24% (29/121) CF patients with Pa infection and in only 17% (3/18) CF patients with no Pa infection. Of the patients with CPA, 29% (20/68) had DCTN4 missense variants vs 23% (8/35) in patients without CPA. Interestingly, p.Tyr263Cys tend to be more frequently observed in CF patients with CPA than in patients without CPA (4/68 vs 0/35), and DCTN4 missense variants tend to be more frequent in male CF patients with CPA bearing two class II mutations than in male CF patients without CPA bearing two class II mutations (P = 0.06). Our observations reinforce that DCTN4 missense variants, especially p.Tyr263Cys, may be involved in the pathogenesis of CPA in male CF.\",\n",
      "  \"candidates\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating standardized mention records...\")\n",
    "\n",
    "train_records = [u.create_mention_record(row) for _, row in df_train.iterrows()]\n",
    "val_records = [u.create_mention_record(row) for _, row in df_val.iterrows()]\n",
    "test_records = [u.create_mention_record(row) for _, row in df_test.iterrows()]\n",
    "print(f\"\\nCreated {len(train_records):,} train records\")\n",
    "print(f\"Created {len(val_records):,} val records\")\n",
    "print(f\"Created {len(test_records):,} test records\")\n",
    "\n",
    "\n",
    "print(\"\\n Example record:\")\n",
    "import json\n",
    "print(json.dumps(train_records[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221ec94e",
   "metadata": {},
   "source": [
    "## Step 6: Export Preprocessed Data\n",
    "\n",
    "**Purpose:** Save processed data in multiple formats optimized for different use cases.\n",
    "\n",
    "**Export formats:**\n",
    "\n",
    "1. **JSONL (JSON Lines):**\n",
    "   - One record per line\n",
    "   - Easy streaming for large datasets\n",
    "   - Human-readable for debugging\n",
    "   - Standard format for NLP pipelines\n",
    "\n",
    "2. **Parquet:**\n",
    "   - Columnar storage (fast loading)\n",
    "   - Efficient compression (smaller files)\n",
    "   - Preserves data types\n",
    "   - Best for pandas/analysis workflows\n",
    "\n",
    "**Output files:**\n",
    "- `train.jsonl` / `train.parquet` - Training data (largest split)\n",
    "- `val.jsonl` / `val.parquet` - Validation for hyperparameter tuning\n",
    "- `test.jsonl` / `test.parquet` - Final evaluation (never used during training)\n",
    "\n",
    "**Why both formats:** JSONL for model training, Parquet for fast analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97dd6ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPORTING PREPROCESSED DATA\n",
      "\n",
      "1. Exporting JSONL format...\n",
      "   train.jsonl\n",
      "   val.jsonl\n",
      "   test.jsonl\n",
      "\n",
      "2. Exporting Parquet format...\n",
      "   train.parquet\n",
      "   val.parquet\n",
      "   test.parquet\n",
      "\n",
      " All exports complete!\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('data/processed/medmentions', exist_ok=True)\n",
    "\n",
    "print(\"EXPORTING PREPROCESSED DATA\")\n",
    "\n",
    "# Format 1: JSONL (for entity linking models)\n",
    "print(\"\\n1. Exporting JSONL format...\")\n",
    "with open('data/processed/medmentions/train.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for record in train_records:\n",
    "        f.write(json.dumps(record) + '\\n')\n",
    "print(\"   train.jsonl\")\n",
    "\n",
    "with open('data/processed/medmentions/val.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for record in val_records:\n",
    "        f.write(json.dumps(record) + '\\n')\n",
    "print(\"   val.jsonl\")\n",
    "\n",
    "with open('data/processed/medmentions/test.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for record in test_records:\n",
    "        f.write(json.dumps(record) + '\\n')\n",
    "print(\"   test.jsonl\")\n",
    "\n",
    "# Format 2: Parquet (for fast loading)\n",
    "print(\"\\n2. Exporting Parquet format...\")\n",
    "df_train_export = pd.DataFrame(train_records)\n",
    "df_val_export = pd.DataFrame(val_records)\n",
    "df_test_export = pd.DataFrame(test_records)\n",
    "\n",
    "df_train_export.to_parquet('data/processed/medmentions/train.parquet', index=False)\n",
    "df_val_export.to_parquet('data/processed/medmentions/val.parquet', index=False)\n",
    "df_test_export.to_parquet('data/processed/medmentions/test.parquet', index=False)\n",
    "print(\"   train.parquet\")\n",
    "print(\"   val.parquet\")\n",
    "print(\"   test.parquet\")\n",
    "\n",
    "print(\"\\n All exports complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55af8db3",
   "metadata": {},
   "source": [
    "## Step 7: Generate Preprocessing Statistics\n",
    "\n",
    "**Purpose:** Create comprehensive statistics report for documentation, analysis, and reproducibility.\n",
    "\n",
    "**Statistics computed:**\n",
    "- **Dataset size:** Number of mentions, documents, unique entities\n",
    "- **Mention characteristics:** Length distribution, abbreviation percentage\n",
    "- **Ambiguity metrics:** How many unique entities per mention\n",
    "- **Context quality:** Average context length\n",
    "- **Split balance:** Distribution across train/val/test\n",
    "\n",
    "**Output:** CSV file with statistics for each split, enabling:\n",
    "- Dataset comparison (AIDA vs MedMentions)\n",
    "- Quality verification (detect issues early)\n",
    "- Paper/presentation metrics\n",
    "- Reproducibility documentation\n",
    "\n",
    "**Use case:** These stats appear in your milestone presentation and help justify why MedMentions is challenging (high abbreviation rate, medical domain complexity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2950943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing preprocessing statistics...\n",
      "\n",
      "MEDMENTIONS PREPROCESSING STATISTICS\n",
      "======================================================================\n",
      "split  num_mentions  num_pmids  num_unique_entities  num_unique_semantic_types  num_abbreviations pct_abbreviations avg_mention_length avg_context_length avg_words_per_mention top_semantic_type  top_semantic_type_count\n",
      "TRAIN        211029       2635                25691                        126              17526             8.31%               10.7               56.8                  1.37              T080                    18689\n",
      "  VAL         71062        878                12610                        124               5744             8.08%               10.7               56.9                  1.37              T080                     6435\n",
      " TEST         70405        879                12419                        123               5922             8.41%               10.7               56.8                  1.37              T080                     6361\n",
      "\n",
      "Statistics saved to preprocessing_stats.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Computing preprocessing statistics...\\n\")\n",
    "\n",
    "train_stats = u.compute_split_statistics(df_train, 'TRAIN')\n",
    "val_stats = u.compute_split_statistics(df_val, 'VAL')\n",
    "test_stats = u.compute_split_statistics(df_test, 'TEST')\n",
    "\n",
    "stats_df = pd.DataFrame([train_stats, val_stats, test_stats])\n",
    "print(\"MEDMENTIONS PREPROCESSING STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(stats_df.to_string(index=False))\n",
    "\n",
    "stats_df.to_csv('data/processed/medmentions/preprocessing_stats.csv', index=False)\n",
    "print(\"\\nStatistics saved to preprocessing_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e83c2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Preprocessing Complete!\n",
    "\n",
    "**Outputs generated:**\n",
    "- `data/processed/medmentions/train.jsonl` + `train.parquet`\n",
    "- `data/processed/medmentions/val.jsonl` + `val.parquet`\n",
    "- `data/processed/medmentions/test.jsonl` + `test.parquet`\n",
    "- `data/processed/medmentions/preprocessing_stats.csv`\n",
    "\n",
    "**Key dataset characteristics:**\n",
    "- üè• **Domain:** Biomedical literature (PubMed abstracts)\n",
    "- üî¨ **Entities:** UMLS concepts (diseases, procedures, chemicals)\n",
    "- üéØ **Challenge:** High ambiguity, especially abbreviations\n",
    "- üìä **Size:** 350K+ mentions, 4K+ documents, 35K+ unique entities\n",
    "\n",
    "**Next steps:**\n",
    "1. Run entity linking analysis (see `Analysis/med_mentions_analysis.ipynb`)\n",
    "2. Compare with AIDA dataset characteristics\n",
    "3. Train Clarify-and-Link model on preprocessed data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
