{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6d70ca0",
   "metadata": {},
   "source": [
    "## Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85057124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import warnings\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f9b6f",
   "metadata": {},
   "source": [
    "## Step 1: Load MedMentions Dataset\n",
    "\n",
    "Parse the PubTator format and split by train/dev/test PMIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f75975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pubtator_file(file_path, max_docs=None):\n",
    "    \"\"\"\n",
    "    Parse PubTator format file and return list of mention dictionaries.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to corpus_pubtator.txt\n",
    "        max_docs: Optional limit on number of documents\n",
    "    \n",
    "    Returns:\n",
    "        List of mention dictionaries with metadata\n",
    "    \"\"\"\n",
    "    mentions = []\n",
    "    current_pmid = None\n",
    "    current_title = \"\"\n",
    "    current_abstract = \"\"\n",
    "    doc_count = 0\n",
    "    \n",
    "    print(f\"Parsing {file_path}...\")\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f):\n",
    "            line = line.rstrip('\\n')\n",
    "            \n",
    "            if not line:  # Empty line = document separator\n",
    "                current_pmid = None\n",
    "                current_title = \"\"\n",
    "                current_abstract = \"\"\n",
    "                continue\n",
    "            \n",
    "            parts = line.split('|')\n",
    "            \n",
    "            if len(parts) == 3:  # Title or abstract line\n",
    "                pmid, line_type, text = parts\n",
    "                if line_type == 't':\n",
    "                    current_pmid = pmid\n",
    "                    current_title = text\n",
    "                    doc_count += 1\n",
    "                    if max_docs and doc_count > max_docs:\n",
    "                        break\n",
    "                elif line_type == 'a':\n",
    "                    current_abstract = text\n",
    "            \n",
    "            elif '\\t' in line:  \n",
    "                fields = line.split('\\t')\n",
    "                if len(fields) >= 6:\n",
    "                    pmid = fields[0]\n",
    "                    start_offset = int(fields[1])\n",
    "                    end_offset = int(fields[2])\n",
    "                    mention_text = fields[3]\n",
    "                    entity_type = fields[4]\n",
    "                    entity_id = fields[5]\n",
    "                    \n",
    "                    \n",
    "                    full_text = current_title + \" \" + current_abstract\n",
    "                    \n",
    "                    # Extract context (200 chars before and after)\n",
    "                    context_window = 200\n",
    "                    context_start = max(0, start_offset - context_window)\n",
    "                    context_end = min(len(full_text), end_offset + context_window)\n",
    "                    \n",
    "                    context_left = full_text[context_start:start_offset]\n",
    "                    context_right = full_text[end_offset:context_end]\n",
    "                    \n",
    "                    mentions.append({\n",
    "                        'pmid': pmid,\n",
    "                        'mention': mention_text,\n",
    "                        'entity_id': entity_id,  \n",
    "                        'entity_type': entity_type,\n",
    "                        'start': start_offset,\n",
    "                        'end': end_offset,\n",
    "                        'context_left': context_left,\n",
    "                        'context_right': context_right,\n",
    "                        'full_context': context_left + \" \" + mention_text + \" \" + context_right,\n",
    "                        'title': current_title,\n",
    "                        'abstract': current_abstract,\n",
    "                        'text': full_text\n",
    "                    })\n",
    "    \n",
    "    print(f\"Parsed {len(mentions)} mentions from {doc_count} documents\")\n",
    "    return mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e8094d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MEDMENTIONS DATASET\n",
      "Parsing data/MedMentions/corpus_pubtator.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "365672it [00:02, 128875.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 352496 mentions from 4392 documents\n",
      "\n",
      "Total mentions: 352,496\n",
      "Total PMIDs: 4,392\n",
      "Total unique UMLS entities: 34,724\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CORPUS_PATH = 'data/MedMentions/corpus_pubtator.txt'\n",
    "TRAIN_PMIDS_PATH = 'data/MedMentions/corpus_pubtator_pmids_trng.txt'\n",
    "DEV_PMIDS_PATH = 'data/MedMentions/corpus_pubtator_pmids_dev.txt'\n",
    "TEST_PMIDS_PATH = 'data/MedMentions/corpus_pubtator_pmids_test.txt'\n",
    "\n",
    "print(\"LOADING MEDMENTIONS DATASET\")\n",
    "\n",
    "mentions_list = parse_pubtator_file(CORPUS_PATH)\n",
    "df_all = pd.DataFrame(mentions_list)\n",
    "\n",
    "print(f\"\\nTotal mentions: {len(df_all):,}\")\n",
    "print(f\"Total PMIDs: {df_all['pmid'].nunique():,}\")\n",
    "print(f\"Total unique UMLS entities: {df_all['entity_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f6c387b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading train/dev/test splits...\n",
      "\n",
      " Split Statistics:\n",
      "Train: 211,029 mentions from 2,635 documents\n",
      "Val:   71,062 mentions from 878 documents\n",
      "Test:  70,405 mentions from 879 documents\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading train/dev/test splits...\")\n",
    "\n",
    "with open(TRAIN_PMIDS_PATH, 'r') as f:\n",
    "    train_pmids = set(f.read().splitlines())\n",
    "\n",
    "with open(DEV_PMIDS_PATH, 'r') as f:\n",
    "    dev_pmids = set(f.read().splitlines())\n",
    "\n",
    "with open(TEST_PMIDS_PATH, 'r') as f:\n",
    "    test_pmids = set(f.read().splitlines())\n",
    "\n",
    "\n",
    "df_train = df_all[df_all['pmid'].isin(train_pmids)].copy()\n",
    "df_val = df_all[df_all['pmid'].isin(dev_pmids)].copy()\n",
    "df_test = df_all[df_all['pmid'].isin(test_pmids)].copy()\n",
    "\n",
    "print(f\"\\n Split Statistics:\")\n",
    "print(f\"Train: {len(df_train):,} mentions from {df_train['pmid'].nunique():,} documents\")\n",
    "print(f\"Val:   {len(df_val):,} mentions from {df_val['pmid'].nunique():,} documents\")\n",
    "print(f\"Test:  {len(df_test):,} mentions from {df_test['pmid'].nunique():,} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec31d062",
   "metadata": {},
   "source": [
    "## Step 2: Filter Valid Entities (Optional)\n",
    "\n",
    "Remove mentions without valid UMLS CUIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f30125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering valid entities...\n",
      "\n",
      "Train:\n",
      "Original: 211,029 | Valid: 211,029 | Removed: 0 (0.00%)\n",
      "\n",
      "Val:\n",
      "Original: 71,062 | Valid: 71,062 | Removed: 0 (0.00%)\n",
      "\n",
      "Test:\n",
      "Original: 70,405 | Valid: 70,405 | Removed: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "def filter_valid_entities(df):\n",
    "    \"\"\"\n",
    "    Keep only mentions with valid UMLS CUIDs.\n",
    "    \"\"\"\n",
    "    original_count = len(df)\n",
    "    \n",
    "    df_filtered = df[(df['entity_id'].notna()) & (df['entity_id'] != '-')].copy()\n",
    "    \n",
    "    filtered_count = len(df_filtered)\n",
    "    removed = original_count - filtered_count\n",
    "    \n",
    "    print(f\"Original: {original_count:,} | Valid: {filtered_count:,} | Removed: {removed:,} ({removed/original_count*100:.2f}%)\")\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "print(\"Filtering valid entities...\")\n",
    "print(\"\\nTrain:\")\n",
    "df_train = filter_valid_entities(df_train)\n",
    "print(\"\\nVal:\")\n",
    "df_val = filter_valid_entities(df_val)\n",
    "print(\"\\nTest:\")\n",
    "df_test = filter_valid_entities(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04c8880",
   "metadata": {},
   "source": [
    "## Step 3: Normalize Mentions\n",
    "\n",
    "Clean and normalize mention text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e4f45aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing mentions...\n",
      "\n",
      "Examples:\n",
      "\n",
      " Normalization complete!\n"
     ]
    }
   ],
   "source": [
    "def normalize_mention(mention):\n",
    "    \"\"\"\n",
    "    Normalize mention text:\n",
    "    - Remove extra whitespace\n",
    "    - Strip leading/trailing punctuation\n",
    "    - Preserve medical abbreviations (keep uppercase)\n",
    "    \"\"\"\n",
    "    normalized = re.sub(r'\\s+', ' ', mention).strip()\n",
    "    \n",
    "    normalized = re.sub(r'^[^\\w-]+|[^\\w-]+$', '', normalized)\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "print(\"Normalizing mentions...\")\n",
    "\n",
    "df_train['normalized_mention'] = df_train['mention'].apply(normalize_mention)\n",
    "df_val['normalized_mention'] = df_val['mention'].apply(normalize_mention)\n",
    "df_test['normalized_mention'] = df_test['mention'].apply(normalize_mention)\n",
    "\n",
    "print(\"\\nExamples:\")\n",
    "sample = df_train.head(10)\n",
    "for orig, norm in zip(sample['mention'], sample['normalized_mention']):\n",
    "    if orig != norm:\n",
    "        print(f\"  '{orig}' → '{norm}'\")\n",
    "\n",
    "print(\"\\n Normalization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5aa794",
   "metadata": {},
   "source": [
    "## Step 4: Extract Biomedical Features\n",
    "\n",
    "Add domain-specific features for medical entity linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8591719b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting biomedical features...\n",
      "\n",
      " Feature Statistics (Train):\n",
      "Abbreviations: 17,526 (8.3%)\n",
      "Mean mention length: 10.7 chars\n",
      "Mean context length: 56.8 words\n",
      "Mean words per mention: 1.37\n",
      "\n",
      "Top 5 semantic types:\n",
      "semantic_type_main\n",
      "T080    18689\n",
      "T169    14241\n",
      "T081    11888\n",
      "T033     9511\n",
      "T116     9194\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def extract_biomedical_features(df):\n",
    "    \"\"\"\n",
    "    Extract biomedical-specific features:\n",
    "    - is_abbreviation: All caps, short (≤6 chars)\n",
    "    - mention_word_count: Number of words in mention\n",
    "    - semantic_type_main: First semantic type from entity_type\n",
    "    \"\"\"\n",
    "    df['is_abbreviation'] = df['mention'].apply(\n",
    "        lambda x: x.isupper() and len(x) <= 6\n",
    "    )\n",
    "    \n",
    "    df['mention_word_count'] = df['mention'].str.split().str.len()\n",
    "    \n",
    "    df['semantic_type_main'] = df['entity_type'].str.split(',').str[0]\n",
    "    \n",
    "    df['mention_length'] = df['mention'].str.len()\n",
    "    \n",
    "    df['context_length'] = df['full_context'].str.split().str.len()\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Extracting biomedical features...\")\n",
    "\n",
    "df_train = extract_biomedical_features(df_train)\n",
    "df_val = extract_biomedical_features(df_val)\n",
    "df_test = extract_biomedical_features(df_test)\n",
    "\n",
    "print(\"\\n Feature Statistics (Train):\")\n",
    "print(f\"Abbreviations: {df_train['is_abbreviation'].sum():,} ({df_train['is_abbreviation'].mean()*100:.1f}%)\")\n",
    "print(f\"Mean mention length: {df_train['mention_length'].mean():.1f} chars\")\n",
    "print(f\"Mean context length: {df_train['context_length'].mean():.1f} words\")\n",
    "print(f\"Mean words per mention: {df_train['mention_word_count'].mean():.2f}\")\n",
    "print(f\"\\nTop 5 semantic types:\")\n",
    "print(df_train['semantic_type_main'].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9119823",
   "metadata": {},
   "source": [
    "## Step 5: Create Mention-Candidate Pairs\n",
    "\n",
    "Format data for entity linking models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edb14ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating standardized mention records...\n",
      "\n",
      "Created 211,029 train records\n",
      "Created 71,062 val records\n",
      "Created 70,405 test records\n",
      "\n",
      " Example record:\n",
      "{\n",
      "  \"pmid\": \"25763772\",\n",
      "  \"mention\": \"DCTN4\",\n",
      "  \"normalized_mention\": \"DCTN4\",\n",
      "  \"context_left\": \"\",\n",
      "  \"context_right\": \" as a modifier of chronic Pseudomonas aeruginosa infection in cystic fibrosis Pseudomonas aeruginosa (Pa) infection in cystic fibrosis (CF) patients is associated with worse long-term pulmonary diseas\",\n",
      "  \"full_context\": \" DCTN4  as a modifier of chronic Pseudomonas aeruginosa infection in cystic fibrosis Pseudomonas aeruginosa (Pa) infection in cystic fibrosis (CF) patients is associated with worse long-term pulmonary diseas\",\n",
      "  \"label_id\": \"C4308010\",\n",
      "  \"entity_type\": \"T116,T123\",\n",
      "  \"semantic_type_main\": \"T116\",\n",
      "  \"start\": 0,\n",
      "  \"end\": 5,\n",
      "  \"is_abbreviation\": true,\n",
      "  \"mention_length\": 5,\n",
      "  \"mention_word_count\": 1,\n",
      "  \"context_length\": 28,\n",
      "  \"title\": \"DCTN4 as a modifier of chronic Pseudomonas aeruginosa infection in cystic fibrosis\",\n",
      "  \"abstract\": \"Pseudomonas aeruginosa (Pa) infection in cystic fibrosis (CF) patients is associated with worse long-term pulmonary disease and shorter survival, and chronic Pa infection (CPA) is associated with reduced lung function, faster rate of lung decline, increased rates of exacerbations and shorter survival. By using exome sequencing and extreme phenotype design, it was recently shown that isoforms of dynactin 4 (DCTN4) may influence Pa infection in CF, leading to worse respiratory disease. The purpose of this study was to investigate the role of DCTN4 missense variants on Pa infection incidence, age at first Pa infection and chronic Pa infection incidence in a cohort of adult CF patients from a single centre. Polymerase chain reaction and direct sequencing were used to screen DNA samples for DCTN4 variants. A total of 121 adult CF patients from the Cochin Hospital CF centre have been included, all of them carrying two CFTR defects: 103 developed at least 1 pulmonary infection with Pa, and 68 patients of them had CPA. DCTN4 variants were identified in 24% (29/121) CF patients with Pa infection and in only 17% (3/18) CF patients with no Pa infection. Of the patients with CPA, 29% (20/68) had DCTN4 missense variants vs 23% (8/35) in patients without CPA. Interestingly, p.Tyr263Cys tend to be more frequently observed in CF patients with CPA than in patients without CPA (4/68 vs 0/35), and DCTN4 missense variants tend to be more frequent in male CF patients with CPA bearing two class II mutations than in male CF patients without CPA bearing two class II mutations (P = 0.06). Our observations reinforce that DCTN4 missense variants, especially p.Tyr263Cys, may be involved in the pathogenesis of CPA in male CF.\",\n",
      "  \"candidates\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def create_mention_record(row):\n",
    "    \"\"\"\n",
    "    Convert dataframe row to standardized mention record.\n",
    "    \"\"\"\n",
    "    record = {\n",
    "        # Core fields\n",
    "        'pmid': row['pmid'],\n",
    "        'mention': row['mention'],\n",
    "        'normalized_mention': row['normalized_mention'],\n",
    "        \n",
    "        # Context\n",
    "        'context_left': row['context_left'],\n",
    "        'context_right': row['context_right'],\n",
    "        'full_context': row['full_context'],\n",
    "        \n",
    "        # Entity information\n",
    "        'label_id': row['entity_id'], \n",
    "        'entity_type': row['entity_type'],\n",
    "        'semantic_type_main': row['semantic_type_main'],\n",
    "        \n",
    "        # Position\n",
    "        'start': row['start'],\n",
    "        'end': row['end'],\n",
    "        \n",
    "        # Features\n",
    "        'is_abbreviation': row['is_abbreviation'],\n",
    "        'mention_length': row['mention_length'],\n",
    "        'mention_word_count': row['mention_word_count'],\n",
    "        'context_length': row['context_length'],\n",
    "        \n",
    "        # Metadata\n",
    "        'title': row['title'],\n",
    "        'abstract': row['abstract'],\n",
    "        \n",
    "        # Placeholder for candidates (to be populated later)\n",
    "        'candidates': []\n",
    "    }\n",
    "    \n",
    "    return record\n",
    "\n",
    "print(\"Creating standardized mention records...\")\n",
    "\n",
    "train_records = [create_mention_record(row) for _, row in df_train.iterrows()]\n",
    "val_records = [create_mention_record(row) for _, row in df_val.iterrows()]\n",
    "test_records = [create_mention_record(row) for _, row in df_test.iterrows()]\n",
    "\n",
    "print(f\"\\nCreated {len(train_records):,} train records\")\n",
    "print(f\"Created {len(val_records):,} val records\")\n",
    "print(f\"Created {len(test_records):,} test records\")\n",
    "\n",
    "\n",
    "print(\"\\n Example record:\")\n",
    "import json\n",
    "print(json.dumps(train_records[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221ec94e",
   "metadata": {},
   "source": [
    "## Step 6: Export Preprocessed Data\n",
    "\n",
    "Save in multiple formats for different use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97dd6ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPORTING PREPROCESSED DATA\n",
      "\n",
      "1. Exporting JSONL format...\n",
      "   train.jsonl\n",
      "   val.jsonl\n",
      "   test.jsonl\n",
      "\n",
      "2. Exporting Parquet format...\n",
      "   train.parquet\n",
      "   val.parquet\n",
      "   test.parquet\n",
      "\n",
      " All exports complete!\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('data/processed/medmentions', exist_ok=True)\n",
    "\n",
    "print(\"EXPORTING PREPROCESSED DATA\")\n",
    "\n",
    "# Format 1: JSONL (for entity linking models)\n",
    "print(\"\\n1. Exporting JSONL format...\")\n",
    "with open('data/processed/medmentions/train.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for record in train_records:\n",
    "        f.write(json.dumps(record) + '\\n')\n",
    "print(\"   train.jsonl\")\n",
    "\n",
    "with open('data/processed/medmentions/val.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for record in val_records:\n",
    "        f.write(json.dumps(record) + '\\n')\n",
    "print(\"   val.jsonl\")\n",
    "\n",
    "with open('data/processed/medmentions/test.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for record in test_records:\n",
    "        f.write(json.dumps(record) + '\\n')\n",
    "print(\"   test.jsonl\")\n",
    "\n",
    "# Format 2: Parquet (for fast loading)\n",
    "print(\"\\n2. Exporting Parquet format...\")\n",
    "df_train_export = pd.DataFrame(train_records)\n",
    "df_val_export = pd.DataFrame(val_records)\n",
    "df_test_export = pd.DataFrame(test_records)\n",
    "\n",
    "df_train_export.to_parquet('data/processed/medmentions/train.parquet', index=False)\n",
    "df_val_export.to_parquet('data/processed/medmentions/val.parquet', index=False)\n",
    "df_test_export.to_parquet('data/processed/medmentions/test.parquet', index=False)\n",
    "print(\"   train.parquet\")\n",
    "print(\"   val.parquet\")\n",
    "print(\"   test.parquet\")\n",
    "\n",
    "print(\"\\n All exports complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55af8db3",
   "metadata": {},
   "source": [
    "## Step 7: Generate Preprocessing Statistics\n",
    "\n",
    "Summary statistics for documentation and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2950943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing preprocessing statistics...\n",
      "\n",
      "MEDMENTIONS PREPROCESSING STATISTICS\n",
      "======================================================================\n",
      "split  num_mentions  num_pmids  num_unique_entities  num_unique_semantic_types  num_abbreviations pct_abbreviations avg_mention_length avg_context_length avg_words_per_mention top_semantic_type  top_semantic_type_count\n",
      "TRAIN        211029       2635                25691                        126              17526             8.31%               10.7               56.8                  1.37              T080                    18689\n",
      "  VAL         71062        878                12610                        124               5744             8.08%               10.7               56.9                  1.37              T080                     6435\n",
      " TEST         70405        879                12419                        123               5922             8.41%               10.7               56.8                  1.37              T080                     6361\n",
      "\n",
      "Statistics saved to preprocessing_stats.csv\n"
     ]
    }
   ],
   "source": [
    "def compute_split_statistics(df, split_name):\n",
    "    \"\"\"\n",
    "    Compute comprehensive statistics for a data split.\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        'split': split_name,\n",
    "        'num_mentions': len(df),\n",
    "        'num_pmids': df['pmid'].nunique(),\n",
    "        'num_unique_entities': df['entity_id'].nunique(),\n",
    "        'num_unique_semantic_types': df['semantic_type_main'].nunique(),\n",
    "        'num_abbreviations': df['is_abbreviation'].sum(),\n",
    "        'pct_abbreviations': f\"{df['is_abbreviation'].mean()*100:.2f}%\",\n",
    "        'avg_mention_length': f\"{df['mention_length'].mean():.1f}\",\n",
    "        'avg_context_length': f\"{df['context_length'].mean():.1f}\",\n",
    "        'avg_words_per_mention': f\"{df['mention_word_count'].mean():.2f}\",\n",
    "        'top_semantic_type': df['semantic_type_main'].value_counts().index[0],\n",
    "        'top_semantic_type_count': df['semantic_type_main'].value_counts().iloc[0]\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "print(\"Computing preprocessing statistics...\\n\")\n",
    "\n",
    "train_stats = compute_split_statistics(df_train, 'TRAIN')\n",
    "val_stats = compute_split_statistics(df_val, 'VAL')\n",
    "test_stats = compute_split_statistics(df_test, 'TEST')\n",
    "\n",
    "stats_df = pd.DataFrame([train_stats, val_stats, test_stats])\n",
    "print(\"MEDMENTIONS PREPROCESSING STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(stats_df.to_string(index=False))\n",
    "\n",
    "stats_df.to_csv('data/processed/medmentions/preprocessing_stats.csv', index=False)\n",
    "print(\"\\nStatistics saved to preprocessing_stats.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
